{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lys06QyJypw",
        "colab_type": "text"
      },
      "source": [
        "*   Name : Pallerla Likhitha\n",
        "*   ID NO : 1700254C203\n",
        "*  SEC : CSE-2\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNIuflKdjiQt",
        "colab_type": "text"
      },
      "source": [
        "**Probelm 1 : Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMClGNMCjve5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(1)\n",
        "\n",
        "allwalks = []\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgCx2rnCkd_k",
        "colab_type": "code",
        "outputId": "c6797fca-2b07-4da0-95a8-15dad892fdcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(250):\n",
        "    randwalk = [0]\n",
        "    for x in range(100):\n",
        "        step = randwalk[-1]\n",
        "        dice = random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + random.randint(1,7)\n",
        "        \n",
        "    print(step)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "3\n",
            "0\n",
            "1\n",
            "3\n",
            "7\n",
            "1\n",
            "1\n",
            "4\n",
            "7\n",
            "0\n",
            "1\n",
            "1\n",
            "7\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "4\n",
            "0\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "6\n",
            "0\n",
            "2\n",
            "4\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "3\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "3\n",
            "2\n",
            "1\n",
            "4\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "6\n",
            "2\n",
            "1\n",
            "5\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "7\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "6\n",
            "1\n",
            "1\n",
            "3\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "2\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "6\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "3\n",
            "0\n",
            "2\n",
            "1\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "4\n",
            "0\n",
            "1\n",
            "1\n",
            "5\n",
            "3\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "7\n",
            "1\n",
            "2\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "4\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "7\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "3\n",
            "0\n",
            "1\n",
            "0\n",
            "1\n",
            "1\n",
            "4\n",
            "7\n",
            "1\n",
            "2\n",
            "2\n",
            "4\n",
            "7\n",
            "0\n",
            "1\n",
            "6\n",
            "0\n",
            "0\n",
            "1\n",
            "1\n",
            "7\n",
            "0\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "5\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxF3I2ONEmON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a84ceb7d-4a2b-4e5b-ebca-925ad6cf0000"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "moves = [1,2,3,4,5,6]\n",
        "prob = [0.2,0.3,0.2,0.1,0.1,0.1]\n",
        "\n",
        "def rollDice():\n",
        "    current_move = np.random.choice(a= moves , p = prob)\n",
        "    return int(current_move) \n",
        "\n",
        "Iterations = 10000\n",
        "down_movement = [1,2]\n",
        "up_movement = [3,4,5]\n",
        "successful_iterations = 0\n",
        "selected6 = 0\n",
        "for i in range (0,Iterations): \n",
        "    total_steps = 250\n",
        "    current_position = 0\n",
        "    selected6 = 0\n",
        "    completedMoves = 0\n",
        "    while completedMoves < total_steps:\n",
        "        completedMoves +=1\n",
        "        if(current_position > 60):\n",
        "            successful_iterations+=1\n",
        "            break\n",
        "        current_movement = rollDice()\n",
        "        if(current_movement in  down_movement):\n",
        "            current_position -=1\n",
        "        elif current_movement in up_movement :\n",
        "            current_position +=1    \n",
        "        else  :#current movement  = 6\n",
        "            completedMoves -=1\n",
        "            current_movement = rollDice()\n",
        "            current_position += current_movement\n",
        "        \n",
        "probabilty_of_reaching = successful_iterations/Iterations\n",
        "print(successful_iterations)\n",
        "print(probabilty_of_reaching)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4241\n",
            "0.4241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gofvM1Gjkn1d",
        "colab_type": "text"
      },
      "source": [
        "**Problem 2 : Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9CRZ8oUk5jN",
        "colab_type": "text"
      },
      "source": [
        " a. Generate random data for for Multiple Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg52Dcgxk702",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import scipy\n",
        "from scipy.stats import norm\n",
        "import pandas as pd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0vS6wtrn8AJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "496afdcc-d046-422b-9085-2294da6bae57"
      },
      "source": [
        "random.seed(1)\n",
        "n= 3\n",
        "X=[]\n",
        "for i in range(0,n):\n",
        "    X_i= scipy.stats.norm.rvs(0, 1, 100)\n",
        "    X.append(X_i)\n",
        "eps=scipy.stats.norm.rvs(0, 1, 100)\n",
        "y = 1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2])  + eps\n",
        "data_ols = {'X0': X[0],'X1':X[1],'X2':X[2] ,'Y': y }\n",
        "df = pd.DataFrame(data_ols)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0 -0.070583 -0.198797  0.522602  2.015094\n",
            "1 -1.055843 -0.301422 -0.789546 -0.956601\n",
            "2  0.424432 -1.016348  1.510032  0.967534\n",
            "3  0.267170 -1.948241 -0.398092  0.086228\n",
            "4 -0.208395 -0.700860  0.435478 -0.177981\n",
            "          X0        X1        X2         Y\n",
            "95  0.708748  1.044930 -0.191773  1.226473\n",
            "96  1.174159  0.471784 -1.130345  2.242354\n",
            "97 -1.121986 -0.718099  0.428745  1.320428\n",
            "98 -0.336709  0.288753  1.199001  0.123871\n",
            "99  0.733376 -0.312411 -0.494704  1.095897\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.051991   -0.067624    0.102169    1.125755\n",
            "std      0.851819    0.935872    0.980516    1.176205\n",
            "min     -2.245315   -2.319569   -2.201674   -1.387844\n",
            "25%     -0.562834   -0.670299   -0.731631    0.276581\n",
            "50%      0.005672   -0.120252    0.081575    1.226455\n",
            "75%      0.677386    0.479422    0.759444    1.925158\n",
            "max      1.921516    2.646797    2.179558    3.970836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AI_sCRDol-F",
        "colab_type": "text"
      },
      "source": [
        "b. Generate random data for for Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgJZS921olF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "828c172a-b4dd-4e22-ad50-a366249b5695"
      },
      "source": [
        "X = []\n",
        "n = 3\n",
        "for i in range(0,n):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "odds = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2])) /(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) ))) \n",
        "y1 = [ ]\n",
        "for i in odds:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2] ,'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0 -0.070583 -0.198797  0.522602  2.015094\n",
            "1 -1.055843 -0.301422 -0.789546 -0.956601\n",
            "2  0.424432 -1.016348  1.510032  0.967534\n",
            "3  0.267170 -1.948241 -0.398092  0.086228\n",
            "4 -0.208395 -0.700860  0.435478 -0.177981\n",
            "          X0        X1        X2         Y\n",
            "95  0.708748  1.044930 -0.191773  1.226473\n",
            "96  1.174159  0.471784 -1.130345  2.242354\n",
            "97 -1.121986 -0.718099  0.428745  1.320428\n",
            "98 -0.336709  0.288753  1.199001  0.123871\n",
            "99  0.733376 -0.312411 -0.494704  1.095897\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.051991   -0.067624    0.102169    1.125755\n",
            "std      0.851819    0.935872    0.980516    1.176205\n",
            "min     -2.245315   -2.319569   -2.201674   -1.387844\n",
            "25%     -0.562834   -0.670299   -0.731631    0.276581\n",
            "50%      0.005672   -0.120252    0.081575    1.226455\n",
            "75%      0.677386    0.479422    0.759444    1.925158\n",
            "max      1.921516    2.646797    2.179558    3.970836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fanTbszYou0f",
        "colab_type": "text"
      },
      "source": [
        "c.Generate random data for for K-Means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXchhk-Po693",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        },
        "outputId": "2e02c77f-e2f2-4c26-b424-d32bf1eb1b75"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmeans = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmeans)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "print(df.info())\n",
        "print(df.describe())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2         Y\n",
            "0 -0.070583 -0.198797  0.522602  2.015094\n",
            "1 -1.055843 -0.301422 -0.789546 -0.956601\n",
            "2  0.424432 -1.016348  1.510032  0.967534\n",
            "3  0.267170 -1.948241 -0.398092  0.086228\n",
            "4 -0.208395 -0.700860  0.435478 -0.177981\n",
            "          X0        X1        X2         Y\n",
            "95  0.708748  1.044930 -0.191773  1.226473\n",
            "96  1.174159  0.471784 -1.130345  2.242354\n",
            "97 -1.121986 -0.718099  0.428745  1.320428\n",
            "98 -0.336709  0.288753  1.199001  0.123871\n",
            "99  0.733376 -0.312411 -0.494704  1.095897\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X0      100 non-null    float64\n",
            " 1   X1      100 non-null    float64\n",
            " 2   X2      100 non-null    float64\n",
            " 3   Y       100 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 3.2 KB\n",
            "None\n",
            "               X0          X1          X2           Y\n",
            "count  100.000000  100.000000  100.000000  100.000000\n",
            "mean     0.051991   -0.067624    0.102169    1.125755\n",
            "std      0.851819    0.935872    0.980516    1.176205\n",
            "min     -2.245315   -2.319569   -2.201674   -1.387844\n",
            "25%     -0.562834   -0.670299   -0.731631    0.276581\n",
            "50%      0.005672   -0.120252    0.081575    1.226455\n",
            "75%      0.677386    0.479422    0.759444    1.925158\n",
            "max      1.921516    2.646797    2.179558    3.970836\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBIw2PWGqDDH",
        "colab_type": "text"
      },
      "source": [
        "**Problem 3 : Solution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ejo6EYPmqHhV",
        "colab_type": "text"
      },
      "source": [
        "a. Linear Regression using Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ke1DEtWwq9Sa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "acb888d3-37f2-4d0e-8ae9-0730c495aa7e"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 150\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.12149951177436703 0.2911363640500372\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwLiJz6RpSwV",
        "colab_type": "text"
      },
      "source": [
        "b. Logistic Regression using Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmpiGThwpX4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "edb33655-966f-4d87-be9c-3b3adde2ca4d"
      },
      "source": [
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.34644190424747157\n",
            "0.346369781888089\n",
            "0.3462989488172553\n",
            "0.346229384471443\n",
            "0.3461610685826626\n",
            "0.34609398117290024\n",
            "0.346028102548775\n",
            "0.3459634132964013\n",
            "0.3458998942764531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-Xprw0kpfQo",
        "colab_type": "text"
      },
      "source": [
        "c. Linear Regression with L1 and L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHKui_xvplbS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "914a51ef-30a9-40b4-b085-29cf7a733a4d"
      },
      "source": [
        "#LINEAR REGRESSION WITH L1 REGULARIZATION\n",
        "\n",
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07505441705331191 0.20387693646821964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmlOON03rFKr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dc11987-4d5b-4ea4-818b-9e34a024b257"
      },
      "source": [
        "# LINEAR REGRESSION WITH L2 REGULARIZATION\n",
        "\n",
        "X = df.iloc[:,0].values\n",
        "#print(X)\n",
        "y = df.iloc[:,3].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.08396480468519651 0.20383226049458464\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmdPwK0crD3a",
        "colab_type": "text"
      },
      "source": [
        "d. Logistic Regression with  L1 and L2 Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBo6DtB0rSh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ea394e94-e20e-4157-976b-781c55a61558"
      },
      "source": [
        "# LOGISTIC REGRESSION WITH L1 REGULARIZATION\n",
        "\n",
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.04757596959853133\n",
            "-0.24880680375518355\n",
            "-0.5427651621834155\n",
            "-0.8343349259661441\n",
            "-1.1235514428001179\n",
            "-1.4104495729654534\n",
            "-1.6950636768518614\n",
            "-1.977427604683284\n",
            "-2.25757468828348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSbuK4ywrZeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "edace003-d347-421a-c55b-b1afcde5eeac"
      },
      "source": [
        "# LOGISTIC REGRESSION WITH L2 REGULARIZATION\n",
        "\n",
        "X1 = df1.iloc[:,0:3].values\n",
        "y1 = df1.iloc[:,3].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((3,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.3465149814264249\n",
            "0.3466566121192769\n",
            "0.34693225938453126\n",
            "0.34733428876441147\n",
            "0.34785539135541144\n",
            "0.34848857151234963\n",
            "0.34922713499079344\n",
            "0.3500646775116872\n",
            "0.35099507373274735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVfZ4zlyri9w",
        "colab_type": "text"
      },
      "source": [
        "e. K-Means"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-PvaOe3rmdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "856881f6-e23f-4dbf-d94d-05c4d6b0d032"
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]\n",
        "\n",
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\"x\", color=color, s=150, linewidths=5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.30974645389135\n",
            "302.92666689742066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V-tJ2yUAnO2",
        "colab_type": "text"
      },
      "source": [
        "**Problem 4: Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1VGeBh-Avr7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ecc263fd-e660-4ad0-e888-51815d6caac8"
      },
      "source": [
        "#Question 1 implemented in oops\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class diceAndStairs:\n",
        "\n",
        "    def  __init__(self ,maxNumberOfTrails , probability):\n",
        "        super().__init__()\n",
        "        self.maxNumberOfTrails = maxNumberOfTrails\n",
        "        self.probabilityList = probability\n",
        "        self.moves  = [1,2,3,4,5,6]\n",
        "        self.down_movement = [1,2]\n",
        "        self.up_movement = [3,4,5]\n",
        "\n",
        "   \n",
        "    def rollDice(self):\n",
        "        current_move = np.random.choice(a= self.moves , p = self.probabilityList)\n",
        "        return int(current_move)  \n",
        "    def findProb(self,Iterations , up_movement , down_movement , prob , desiredSteps):\n",
        "        successful_iterations = 0\n",
        "        selected6 = 0\n",
        "        for i in range (0,Iterations): \n",
        "            total_steps = self.maxNumberOfTrails\n",
        "            current_position = 0\n",
        "            selected6 = 0\n",
        "            completedMoves = 0\n",
        "            while completedMoves < total_steps:\n",
        "                completedMoves +=1\n",
        "                if(current_position > desiredSteps):\n",
        "                    successful_iterations+=1\n",
        "                    break\n",
        "                current_movement = self.rollDice()\n",
        "                if(current_movement in  down_movement):\n",
        "                    current_position -=1\n",
        "                elif current_movement in up_movement :\n",
        "                    current_position +=1    \n",
        "                else  :#current movement  = 6\n",
        "                    completedMoves -=1\n",
        "                    current_movement = self.rollDice()\n",
        "                    current_position += current_movement\n",
        "                \n",
        "        probabilty_of_reaching = successful_iterations/Iterations\n",
        "        print(successful_iterations)\n",
        "        print(probabilty_of_reaching)\n",
        "    \n",
        "    def findProbabilityOfReaching(self , desiredSteps , Iterations):\n",
        "        self.findProb(Iterations,self.up_movement,self.down_movement,self.probabilityList,desiredSteps)\n",
        "    \n",
        "\n",
        "moves = [1,2,3,4,5,6]\n",
        "prob = [0.2,0.3,0.2,0.1,0.1,0.1]\n",
        "dc =  diceAndStairs(250 , prob)\n",
        "dc.findProbabilityOfReaching(60 , 10000)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4203\n",
            "0.4203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHxL_D21sPsH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Question 2 \n",
        "\n",
        "# Linear Regression using Gradient Descent\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) \n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "    if __name__ == \"__main__\": main()\n",
        "\n",
        "# Logistic Regression with Gradient Descent\n",
        "\n",
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}